{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "92778525",
      "metadata": {
        "id": "92778525"
      },
      "source": [
        "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
        "### Due: October 10 at 11:59pm\n",
        "\n",
        "### Name: Mohammed Atifkhan Pathan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "## Part 1: Classification (14.5 marks total)\n",
        "\n",
        "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3c6fc8",
      "metadata": {
        "id": "7e3c6fc8"
      },
      "source": [
        "### Step 0: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "33f86925",
      "metadata": {
        "id": "33f86925"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "### Step 1: Data Input (1 mark)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
        "\n",
        "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print the size and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "33583c67",
      "metadata": {
        "id": "33583c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c783c4ab-652c-4df4-e9bb-4d764d96d56e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X is 262200\n",
            "Shape of X is (4600, 57)\n",
            "Type of X is DataFrame\n",
            "\n",
            "\n",
            "Size of y is 4600\n",
            "Shape of y is (4600,)\n",
            "Type of y is Series\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Import spam dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_spam\n",
        "X, y = load_spam()\n",
        "# TO DO: Print size and type of X and y\n",
        "print(\"Size of X is\", X.size)\n",
        "print(\"Shape of X is\", X.shape)\n",
        "print(\"Type of X is\", type(X).__name__)\n",
        "print(\"\\n\")\n",
        "print(\"Size of y is\", y.size)\n",
        "print(\"Shape of y is\", y.shape)\n",
        "print(\"Type of y is\", type(y).__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "### Step 2: Data Processing (1.5 marks)\n",
        "\n",
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4e7204f5",
      "metadata": {
        "id": "4e7204f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff816611-5d52-40f6-da16-7f922de0de11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of missing values in X are 0\n",
            "The total number of missing values in y are 0\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Check if there are any missing values and fill them in if necessary\n",
        "print(\"The total number of missing values in X are\", X.isnull().sum().sum())\n",
        "print(\"The total number of missing values in y are\", y.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, no need to fill any values as there are no missing values in the dataset"
      ],
      "metadata": {
        "id": "G5VFPEieBmP7"
      },
      "id": "G5VFPEieBmP7"
    },
    {
      "cell_type": "markdown",
      "id": "a489285a",
      "metadata": {
        "id": "a489285a"
      },
      "source": [
        "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f9bc4a23",
      "metadata": {
        "id": "f9bc4a23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba6d69f-1683-4ce6-d270-05e37b6d36bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of X is 4600 , 5% of that is 230.0\n",
            "Shape of X_small is (230, 57)\n",
            "Shape of y_small is (230,)\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Create X_small and y_small\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "_, X_small, _, y_small = train_test_split(X, y,\n",
        "                                          test_size=0.05,\n",
        "                                          stratify=y,\n",
        "                                          random_state=0)\n",
        "\n",
        "print(\"Length of X is\", len(X), \", 5% of that is\", 0.05*len(X))\n",
        "print(\"Shape of X_small is\", X_small.shape)\n",
        "print(\"Shape of y_small is\", y_small.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of X_small and y_small matches that of 5% of the data"
      ],
      "metadata": {
        "id": "nHSAMlkb1pWY"
      },
      "id": "nHSAMlkb1pWY"
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "### Step 3: Implement Machine Learning Model\n",
        "\n",
        "1. Import `LogisticRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Implement the machine learning model with three different datasets:\n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b89f3d84",
      "metadata": {
        "id": "b89f3d84"
      },
      "source": [
        "### Step 4: Validate Model\n",
        "\n",
        "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "352106a3",
      "metadata": {
        "id": "352106a3"
      },
      "source": [
        "### Step 5: Visualize Results (4 marks)\n",
        "\n",
        "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
        "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "be4b5c0a",
      "metadata": {
        "id": "be4b5c0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a068d300-40c8-4f31-c6c7-d682bb19dbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "\n",
            "  Data size  Training accuracy  Validation accuracy\n",
            "0    262200           0.933043             0.930435\n",
            "1      9200           0.619420             0.605217\n",
            "2     13110           0.930233             0.913793\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Instantiate model\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "# Create an empty dataframe to store the results\n",
        "results = pd.DataFrame(columns=['Data size', 'Training accuracy', 'Validation accuracy'])\n",
        "\n",
        "# make another copy of X with just first 2 columns\n",
        "X_two_col = X.iloc[:, :2]\n",
        "\n",
        "# Implement machine learning models with different datasets\n",
        "for X_vals, y_vals in zip([X, X_two_col, X_small],[y, y, y_small]):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_vals, y_vals, stratify=y_vals, random_state=0)\n",
        "    logreg = model.fit(X_train, y_train)\n",
        "    val_acc = logreg.score(X_test, y_test)\n",
        "    train_acc = logreg.score(X_train, y_train)\n",
        "    new_row = pd.DataFrame({\n",
        "        'Data size': [X_vals.size],\n",
        "        'Training accuracy': [train_acc],\n",
        "        'Validation accuracy': [val_acc]\n",
        "    })\n",
        "    results = pd.concat([results, new_row], ignore_index=True)\n",
        "print(\"Results:\\n\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4427d4f",
      "metadata": {
        "id": "d4427d4f"
      },
      "source": [
        "### Questions (4 marks)\n",
        "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
        "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
        "\n",
        "Answer:\n",
        "1. As seen from the printed results, the data size with the highest accuracy is the biggest in size: `262,200` vs the worst accuracy being the lowest size: `9,200`. This means that less data can significantly impact the training and validation accuracies.\n",
        "\n",
        "  Now, looking further into the values, lets compare the full dataset with the 5% of the dataset. Here, the accuracies are similar yet still _lower for the smaller set_. However, interestingly, the validation score is even lower in comparision. This can be due to the fact that there is even less _new_ data to test the accuracy against. Meaning, each wrong prediction will matter more in terms of percentage but also due to the small train set, the test set could be more challenging for the model to predict.\n",
        "\n",
        "  The reason the `5% dataset` and the `2 columns` of X data set are so different in accuracy even when the apparent _size_ is very similar is because of the way the data was split essentially. The 5% is a percentage of the whole data, so includes all the columns and `5% of the total instances/rows`, sampling a subset of the data without losing features. The sampling may reduce the data but in this case it seems it was still big enough to generalize and predict with high accuracy. This is very different than only using 2 columns from X. This means there are _only `2 features`_ taken into account. This means that you have essentially simplified the data by removing different features (words that are used rto filter spam) and in turn, removing information that the model could use to make accurate predictions. Basically, instead of using multiple differnt words to predict spam, model only used two words. Hence, the accuracy of the model suffers significantly.\n",
        "\n",
        "2. A false positive would mean that a mail was good but identified as a spam. A false negative would mean that a mail was spam and was not filtered (not identified as spam). In this case the worse option is filtering out good mail by wrongly classifying it as spam as it could be an important email. With the other category, it may always be hard to predict and filter out all spam emails. But a human can be the second defense and look at the email and filter spams that may not have been filtered initially."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7559517a",
      "metadata": {
        "id": "7559517a"
      },
      "source": [
        "### Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59fe687f",
      "metadata": {
        "id": "59fe687f"
      },
      "source": [
        "1. The process was fairly simple. The code was sourced mainly from my own knowledge and using the notes/examples given in class. There were instances when I had to use generativeAI for help mainly with syntax related issues.\n",
        "2. I think the steps outlined were well organized so I tried to follow the steps as it is. I did realise after I got to step five that I had to make a loop so I had to go back and essentially fit steps 3, 4, and 5 into one.\n",
        "3. The prompts I used were mainly in regards to explaining things or snippets of code. For example: `\"Create a pandas DataFrame results with columns: Data size, training accuracy, validation accuracy\"` or `\"how can I use only the first two columns of a dataframe\"`. I find it very helpful for things like syntax and explaining snippets of code. I did have to adjust the code to fit my problem and variables.\n",
        "4. The biggest challenge with using chatgpt is that even with context it is hard to explain exactly what you need. And since its generativeAI it is predicting text from stuff it has seen, which is code that does not always apply to what I want. The most success I have found is on smaller scale things. If I have a solution in mind and I know the overall steps, I can breakdown the steps and ask it to help one at a time on independant things and then combine it all myself. That is mainly how I have started to use chatgpt as it often struggles if you copy paste a whole code snippet plus problem question and all the required delivarables all at once. Its answers are sometimes not detailed, not relavant, incomplete etc.\n",
        "\n",
        "Tools and websites used:\n",
        "- ChatGPT\n",
        "- BingAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb4c78a8",
      "metadata": {
        "id": "fb4c78a8"
      },
      "source": [
        "## Part 2: Regression (10.5 marks total)\n",
        "\n",
        "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ba83c5",
      "metadata": {
        "id": "b2ba83c5"
      },
      "source": [
        "### Step 1: Data Input (1 mark)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print the size and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "6ff2e34f",
      "metadata": {
        "id": "6ff2e34f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5f3791-f2f3-4d5d-da13-88de8eab5aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X is 8240\n",
            "Shape of X is (1030, 8)\n",
            "Type of X is DataFrame\n",
            "\n",
            "\n",
            "Size of y is 1030\n",
            "Shape of y is (1030,)\n",
            "Type of y is Series\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Import spam dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_concrete\n",
        "X, y = load_concrete()\n",
        "# TO DO: Print size and type of X and y\n",
        "print(\"Size of X is\", X.size)\n",
        "print(\"Shape of X is\", X.shape)\n",
        "print(\"Type of X is\", type(X).__name__)\n",
        "print(\"\\n\")\n",
        "print(\"Size of y is\", y.size)\n",
        "print(\"Shape of y is\", y.shape)\n",
        "print(\"Type of y is\", type(y).__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5294cfa",
      "metadata": {
        "id": "c5294cfa"
      },
      "source": [
        "### Step 2: Data Processing (0.5 marks)\n",
        "\n",
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "693c5fa3",
      "metadata": {
        "id": "693c5fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3871299-de45-4b5c-ded4-67d8c39f2883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of missing values in X are 0\n",
            "The total number of missing values in y are 0\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Check if there are any missing values and fill them in if necessary\n",
        "print(\"The total number of missing values in X are\", X.isnull().sum().sum())\n",
        "print(\"The total number of missing values in y are\", y.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, no need to fill any values as there are no missing values in the dataset"
      ],
      "metadata": {
        "id": "qM0-bEilJ27v"
      },
      "id": "qM0-bEilJ27v"
    },
    {
      "cell_type": "markdown",
      "id": "1bc60489",
      "metadata": {
        "id": "1bc60489"
      },
      "source": [
        "### Step 3: Implement Machine Learning Model (1 mark)\n",
        "\n",
        "1. Import `LinearRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Implement the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b5041945",
      "metadata": {
        "id": "b5041945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "7fb9be19-f589-491e-d517-bf6e6c1c016f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "# Initialize and train a linear regression model\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1de28482",
      "metadata": {
        "id": "1de28482"
      },
      "source": [
        "### Step 4: Validate Model (1 mark)\n",
        "\n",
        "Calculate the training and validation accuracy using mean squared error and R2 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "970c038b",
      "metadata": {
        "id": "970c038b"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Make predictions\n",
        "train_ypred = linear_model.predict(X_train)\n",
        "val_ypred = linear_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54aa7795",
      "metadata": {
        "id": "54aa7795"
      },
      "source": [
        "### Step 5: Visualize Results (1 mark)\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
        "2. Add the accuracy results to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "88d223f3",
      "metadata": {
        "id": "88d223f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "53ee67db-15c5-40dd-95bf-2d227c387e70"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          Training accuracy  Validation accuracy\n",
              "MSE              111.358439            95.904136\n",
              "R2 score           0.610823             0.623414"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6db8a67-69c3-4b73-8a18-95be1b95e6b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training accuracy</th>\n",
              "      <th>Validation accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MSE</th>\n",
              "      <td>111.358439</td>\n",
              "      <td>95.904136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R2 score</th>\n",
              "      <td>0.610823</td>\n",
              "      <td>0.623414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6db8a67-69c3-4b73-8a18-95be1b95e6b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6db8a67-69c3-4b73-8a18-95be1b95e6b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6db8a67-69c3-4b73-8a18-95be1b95e6b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2a29d8a-40ea-4e94-8cdc-b04a61bed446\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2a29d8a-40ea-4e94-8cdc-b04a61bed446')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2a29d8a-40ea-4e94-8cdc-b04a61bed446 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "# Create a dataframe to store the results\n",
        "results = pd.DataFrame({'Training accuracy': [0, 0],\n",
        "                        'Validation accuracy': [0, 0]},\n",
        "                        index=['MSE', 'R2 score'])\n",
        "\n",
        "# calculate accuracy results and update results\n",
        "results.loc['MSE'] = [mean_squared_error(y_train, train_ypred), mean_squared_error(y_test, val_ypred)]\n",
        "results.loc['R2 score'] = [r2_score(y_train, train_ypred), r2_score(y_test, val_ypred)]\n",
        "\n",
        "display(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70a42bda",
      "metadata": {
        "id": "70a42bda"
      },
      "source": [
        "### Questions (2 marks)\n",
        "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
        "\n",
        "I dont think the result was that good since the R2 score was `~0.6` and MSE was `~100` which is not very close to 0. However, it could be considered decent. I think using a linear model for this dataset is not a good idea however, because as described on the yellowbricks page, the relationship between the features (ingredients and age) and the target (concrete compressive strength) is highly nonlinear. Thus, its not the best to try to use a linear regression model for this and why the results were okay to not good."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca0ff2f",
      "metadata": {
        "id": "2ca0ff2f"
      },
      "source": [
        "### Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfdb0880",
      "metadata": {
        "id": "dfdb0880"
      },
      "source": [
        "1. The code was sourced mainly from my own knowledge and using the notes/examples given in class. There were instances when I had to use generativeAI for help in understanding the different accuracy metrics.\n",
        "2. I think the steps outlined were well organized so I followed the steps as is.\n",
        "3. The prompts I used were mainly in regards to explaining the accuracy metrics and how to interpret them. For example: `\"What does R2 score and MSE of a model describe\"` or `\"My scores were xx and xx, how do I interpret them in this context\"`. Since there was no code being generated I did not have to adjust anything. It explained to me what I needed to understand to answer questions.\n",
        "4. The biggest challenge with using chatgpt is that even with context it is hard to explain exactly what you need. And since its generativeAI it is predicting text from stuff it has seen, which is code that does not always apply to what I want. The most success I have found is on smaller scale things. In my example, I used it to explain concepts or use things in an example to make it easier to understand. Then I can look at my own results and apply that understanding to it.\n",
        "\n",
        "Tools and websites used:\n",
        "- ChatGPT\n",
        "- BingAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72ac3eb",
      "metadata": {
        "id": "e72ac3eb"
      },
      "source": [
        "## Part 3: Observations/Interpretation (3 marks)\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "The only pattern I see is the whole machine learning framework itself. As mentioned in class as well, the steps for these analyses and creating models and getting the data ready are relatively the same. They can all be reduced to 4-5 parts as described in the two different problems above.\n",
        "\n",
        "But in terms of quantitative patterns, I think the classification problem had a pattern of `more data = higher accuracy`. For example, the size of the whole data vs 5% of the data. The validation scores for the 5% was ~0.92 and for the whole data was ~0.93.\n",
        "\n",
        "Another observation was that a problem requires not only sufficient data but _also_ the relavant model. We saw that in problem 2, the model was not best suited for the data and relationship between the data. Even with over a 1000 points available, a linear model is not best for a very non-linear relationship. The scores (R^2 and MSE) were not indicitive of a highly accurate model as 0.6 and 100 are not very good scores, especially in the context of determining concrete compressive strength based on the age/ingredients of that concrete.\n",
        "\n",
        "This shows that machine learning challenge lies more in the selection of models, experimentation of fine tuning parameters and feeding larger and full data. This is ultimately even more depandant on the problem itself as different approaches will yield different results based on the problem. And even after having everything \"right\" the results can also be interpreted differently based on the context of the problem. Where even a high accuracy score (92% for example) may not be good enough and in other cases, even a lower score might do.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b84eed",
      "metadata": {
        "id": "40b84eed"
      },
      "source": [
        "## Part 4: Reflection (2 marks)\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "I liked that this assignment is very structred. It makes it less confusing and easier to get through the code of it and focus on what the results ential.\n",
        "\n",
        "I found the datasets interesting. They were simple and made the calculations easy but I could see what a real world example could be which was cool."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db951b3a",
      "metadata": {
        "id": "db951b3a"
      },
      "source": [
        "## Part 5: Bonus Question (4 marks)\n",
        "\n",
        "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
        "\n",
        "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47623d44",
      "metadata": {
        "id": "47623d44"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b606236",
      "metadata": {
        "id": "1b606236"
      },
      "source": [
        "*ANSWER HERE*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}